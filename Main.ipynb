{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataSet\n",
    "import Evaluation\n",
    "import datetime\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from Utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a bunch of parameters the expriment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================================================\n",
    "# Give this run a name. \n",
    "# If name equals 'test', no log will be generated\n",
    "#===========================================================================\n",
    "name = 'test'\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Decide which gesture data shall be used for training\n",
    "#===========================================================================\n",
    "inputGestures = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "#===========================================================================\n",
    "# Decide which target signals shall be used for training\n",
    "#===========================================================================\n",
    "usedGestures = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "#===========================================================================\n",
    "# Concatenate data to create \"more\" training samples, 1 corresponds to no concatenations\n",
    "#===========================================================================\n",
    "concFactor = 1\n",
    "\n",
    "#===========================================================================\n",
    "# Add noise to the data, 0 corresponds to no noise. Noise above 2 has shown to weaken recognition\n",
    "#===========================================================================\n",
    "noiseFactor = 1\n",
    "\n",
    "#===========================================================================\n",
    "# Decide wether gestures shall be shuffled before training. If true, nFolds many \n",
    "# pieces will be generated. Not every piece is garanteed to contain every gesture, so do not use too many.\n",
    "#===========================================================================\n",
    "shuffle = True\n",
    "nFolds = 4\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Function used to evaluate during cross validation. Possible functions are:\n",
    "# Evaluation.calc1MinusF1FromMaxApp (best working, used in thesis)\n",
    "# Oger.utils.nmse (normalised mean square error, tells nothing about classifier perfomance but works okay)\n",
    "# Evaluation.calcLevenshteinError (use the Levenshtein error, disadvantages are highlighted in thesis) \n",
    "# Evaluation.calc1MinusF1FromInputSegment (use segmentation by supervised signal)\n",
    "#===========================================================================\n",
    "evaluationFunction = Evaluation.calc1MinusF1FromMaxApp\n",
    "\n",
    "#===========================================================================\n",
    "# Set this to true if another output neuron shall be added to represent \"no gesture\"\n",
    "#===========================================================================\n",
    "learnTreshold = True\n",
    "\n",
    "#===========================================================================\n",
    "# Use on of the optimisation dictionaries from the optDicts file\n",
    "#===========================================================================\n",
    "optDict = 'bestParas'\n",
    "\n",
    "#===========================================================================\n",
    "# Use normalizer\n",
    "#===========================================================================\n",
    "useNormalized = 2\n",
    "\n",
    "#===========================================================================\n",
    "# Pick datasets to train on, and datasets to test on\n",
    "#===========================================================================\n",
    "inputFiles = ['nike','julian','nadja','line']\n",
    "testFiles = ['stephan']\n",
    "\n",
    "# If desired add a specific file to test on, e.g. randTestFiles = ['lana_0_0.npz']\n",
    "randTestFiles = []\n",
    "\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Setup project directory\n",
    "#===========================================================================\n",
    "now = datetime.datetime.now()\n",
    "resultsPath = getProjectPath()+'results/'\n",
    "pdfFileName = now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.pdf'\n",
    "pdfFilePath = resultsPath+'pdf/'+pdfFileName\n",
    "npzFileName = now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.npz'\n",
    "npzFilePath = resultsPath+'npz/'+npzFileName\n",
    "bestFlowPath = resultsPath+'nodes/'+now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.p'\n",
    "pp = PdfPages(pdfFilePath)\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Add labels for gestures\n",
    "#===========================================================================\n",
    "totalGestureNames = ['left','right','forward','backward','bounce up','bounce down','turn left','turn right','shake lr','shake ud', \\\n",
    "                     'tap 1','tap 2','tap 3','tap 4','tap 5','tap 6','no gesture']\n",
    "gestureNames = []\n",
    "for i in usedGestures:\n",
    "    gestureNames.append(totalGestureNames[i])\n",
    "gestureNames.append('no gesture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: dataset should be moved to Dataset.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class UniHHIMUGestures(Dataset):\n",
    "    \n",
    "\n",
    "    def __init__(self, \n",
    "                 dataDir='dataSets/',\n",
    "                 inputFiles=['nike','julian','nadja','line'], testFiles=['stephan'], train=True, \n",
    "                 inputGestures=[0,1,2,3,4,5,6,7,8,9], \n",
    "                 usedGestures=[0,1,2,3,4,5,6,7,8,9], \n",
    "                 useNormalized=2, \n",
    "                 shuffle=True, nFolds=4, nRepeat=1, noiseFactor=1, learnTreshold=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputFiles (list<string>): Files/people to be used in trainset.\n",
    "            testFiles (list<string>): Files/people to be used in testset.\n",
    "            train (bool): wether or not the get method will return train or test samples\n",
    "            useNormalized (int): normalisation of input signal. \n",
    "                0: no normalisation\n",
    "                1: scale each sensors std to 1\n",
    "                2: scale each sensors max value to 1 \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.train = train\n",
    "        self.useNormalized = useNormalized\n",
    "        \n",
    "        \n",
    "        # ===================================================================\n",
    "        # Create trainset\n",
    "        # ===================================================================\n",
    "        \n",
    "        \n",
    "        dataStep = []\n",
    "        for fileName in inputFiles:\n",
    "            ind, t  = DataSet.createData(fileName, inputGestures,usedGestures, dataDir=dataDir)\n",
    "            dataStep.append((ind,t))\n",
    "\n",
    "        # calculate normalizers from train files\n",
    "        inputs = np.concatenate([inputs for inputs, targets in dataStep])\n",
    "        self.normalizer = np.ones(9)\n",
    "        if self.useNormalized == 1:\n",
    "            self.normalizer[0:3] = np.std(np.linalg.norm(inputs[:,0:3], None, 1))\n",
    "            self.normalizer[3:6] = np.std(np.linalg.norm(inputs[:,3:6], None, 1))\n",
    "            self.normalizer[6:9] = np.std(np.linalg.norm(inputs[:,6:9], None, 1))\n",
    "        if self.useNormalized == 2:\n",
    "            self.normalizer[0:3] = np.max(np.linalg.norm(inputs[:,0:3], None, 1))\n",
    "            self.normalizer[3:6] = np.max(np.linalg.norm(inputs[:,3:6], None, 1))\n",
    "            self.normalizer[6:9] = np.max(np.linalg.norm(inputs[:,6:9], None, 1))\n",
    "\n",
    "            \n",
    "        # if desired shuffle and rearrage the data in nFolds\n",
    "        # each fold can contain gestures from each person in the trainset, but not from the testset person \n",
    "        if(shuffle):\n",
    "            dataStep = shuffleDataStep(dataStep, nFolds=nFolds, nRepeat=nRepeat)\n",
    "\n",
    "\n",
    "        self.train_data = []\n",
    "        for ind, t in dataStep:\n",
    "\n",
    "            ind[:,0:3] += np.random.normal(0,0.05 *noiseFactor, size=(len(ind),3))\n",
    "            ind[:,3:6] += np.random.normal(0,0.5 * noiseFactor, size=(len(ind),3))\n",
    "            ind[:,6:9] += np.random.normal(0,1.25 * noiseFactor, size=(len(ind),3))\n",
    "\n",
    "            # if treshold shall be learned, another target signal needs to be added. \n",
    "            # No gestures signal is 1 if all other targets are 0 and -1 otherwise.\n",
    "            if learnTreshold:\n",
    "                t = np.append(t,1-2*t.max(1, keepdims=True),1)\n",
    "\n",
    "            self.train_data.append((ind,t))\n",
    "            \n",
    "            \n",
    "        # ===================================================================\n",
    "        # Create testset\n",
    "        # ===================================================================\n",
    "        dataStep = []\n",
    "        for fileName in testFiles:\n",
    "            ind, t  = DataSet.createData(fileName, inputGestures,usedGestures, dataDir=dataDir)\n",
    "            dataStep.append((ind,t))\n",
    "        \n",
    "        if shuffle:\n",
    "            test_data = shuffleDataStep(dataStep, nFolds=1, nRepeat=1)\n",
    "        self.test_data = test_data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            inputs, targets = self.train_data[idx]\n",
    "        else:\n",
    "            inputs, targets = self.test_data[idx]\n",
    "        \n",
    "        inputs /= self.normalizer\n",
    "        \n",
    "        return inputs, targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = UniHHIMUGestures(dataDir='dataSets/', train=True, useNormalized=useNormalized)\n",
    "testset = UniHHIMUGestures(dataDir='dataSets/', train=False, useNormalized=useNormalized)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=1,\n",
    "                        shuffle=True, num_workers=1)\n",
    "testloader = DataLoader(testset, batch_size=1,\n",
    "                        shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the scaled input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(20,9))\n",
    "ax[0].plot(trainset[0][0][:800,0:3])\n",
    "ax[1].plot(trainset[0][0][:800,3:6])\n",
    "ax[2].plot(trainset[0][0][:800,6:9])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks all good, we can clearly see the gesture sequences intercepted by non gesture seqeuences in between.\n",
    "Now let's create a Leaky Integrator ESN with parameters as defined in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from echotorch.nn.ESN import ESN\n",
    "from echotorch.nn.LiESN import LiESN\n",
    "\n",
    "\n",
    "\n",
    "esn = LiESN(\n",
    "    input_dim=9,\n",
    "    hidden_dim=400,\n",
    "    output_dim=10,\n",
    "    input_scaling=13.,\n",
    "    sparsity=0.1, # input matrix sparsity\n",
    "    w_distrib='gaussian',\n",
    "    spectral_radius=1.,\n",
    "    bias_scaling=0., # no input bias\n",
    "    feedbacks=False, # No feedback connections\n",
    "    learning_algo='inv',\n",
    "    leaky_rate=.3\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Training is done automatically when presenting the values and targets to the network. After calling finalize training is completed and network switches to prediction mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for inputs, targets in trainloader:\n",
    "    inputs, targets = Variable(inputs.float()), Variable(targets.float())\n",
    "    esn(inputs, targets)\n",
    "    \n",
    "esn.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Plot activations of network on testset and corresponding target signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_inputs, test_targets in testloader:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    outputs = esn(test_inputs.float())\n",
    "    plt.plot(outputs[0,:800,:])\n",
    "    plt.plot(test_targets[0,:800,:])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "trainCms = []\n",
    "trainF1MaxApps = []\n",
    "trainPredicitions = []\n",
    "trainTargets = []\n",
    "trainF1s = []\n",
    "\n",
    "prediction = outputs[0].numpy()\n",
    "t_target =  test_targets[0].numpy()\n",
    "\n",
    "pred, targ = Evaluation.calcInputSegmentSeries(prediction, t_target, 0.4, False)\n",
    "trainF1s.append(np.mean(sklearn.metrics.f1_score(targ,pred,average=None)))\n",
    "\n",
    "\n",
    "t_maxApp_prediction = Evaluation.calcMaxActivityPrediction(prediction,t_target,0.5,10)\n",
    "pred_MaxApp, targ_MaxApp = Evaluation.calcInputSegmentSeries(t_maxApp_prediction, t_target, 0.5)\n",
    "trainF1MaxApps.append(np.mean(sklearn.metrics.f1_score(targ_MaxApp,pred_MaxApp,average=None)))\n",
    "\n",
    "conf = sklearn.metrics.confusion_matrix(targ_MaxApp, pred_MaxApp)\n",
    "trainCms.append(conf)\n",
    "trainPredicitions.append(prediction)\n",
    "trainTargets.append(t_target)\n",
    "\n",
    "Evaluation.plot_confusion_matrix(trainCms[0], gestureNames, 'test set')\n",
    "plt.tight_layout()\n",
    "plt.ylim(10.5,-0.5)\n",
    "\n",
    "print(\"Test f1 score for maxactivity: {:.2f}\".format(trainF1MaxApps[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: why is the testscore here lower than in OGER? supposed to be 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "Create and train LSTM on the give data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=25):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_size=9, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim,10, bias=False),\n",
    "            #torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        \n",
    "        lstm_outputs, (hidden_acts, cell_states) = self.lstm(inputs)\n",
    "        predictions = self.classifier(lstm_outputs)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lstm = LSTMClassifier(25)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = optim.SGD(lstm.parameters(), lr=1e-1)\n",
    "\n",
    "\n",
    "for epoch in range(101):\n",
    "    for inputs, targets in trainloader:\n",
    "\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        \n",
    "        inputs[0,:,:9] = targets[0,:,:9]\n",
    "\n",
    "        lstm.zero_grad()\n",
    "\n",
    "        outputs =  lstm(inputs)\n",
    "\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        lstm.lstm\n",
    "        \n",
    "        optimizer.step()\n",
    "    if epoch % 2 == 0:\n",
    "        print(loss.item())\n",
    "        lstm.eval()\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.title('Epoch: {:}, loss: {:.4f}'.format(epoch, loss))\n",
    "        test_preds = lstm(test_inputs.float()).detach().numpy()[0]\n",
    "        plt.plot(test_preds[:800,:])\n",
    "        plt.plot(test_targets[0,:800,:])\n",
    "        plt.ylim(-0.1,1.1)\n",
    "        plt.pause(1)\n",
    "        lstm.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.eval()\n",
    "plt.figure(figsize=(20,5))\n",
    "test_preds = lstm(test_inputs.float()).detach().numpy()[0]\n",
    "plt.plot(test_preds[:800,:])\n",
    "plt.pause(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
