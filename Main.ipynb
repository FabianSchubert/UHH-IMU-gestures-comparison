{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataSet\n",
    "import Evaluation\n",
    "import datetime\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from Utils import *\n",
    "\n",
    "from DataSet import UniHHIMUGestures\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a bunch of parameters the expriment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================================================\n",
    "# Give this run a name. \n",
    "# If name equals 'test', no log will be generated\n",
    "#===========================================================================\n",
    "name = 'test'\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Decide which gesture data shall be used for training\n",
    "#===========================================================================\n",
    "inputGestures = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "#===========================================================================\n",
    "# Decide which target signals shall be used for training\n",
    "#===========================================================================\n",
    "usedGestures = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "#===========================================================================\n",
    "# Concatenate data to create \"more\" training samples, 1 corresponds to no concatenations\n",
    "#===========================================================================\n",
    "concFactor = 1\n",
    "\n",
    "#===========================================================================\n",
    "# Add noise to the data, 0 corresponds to no noise. Noise above 2 has shown to weaken recognition\n",
    "#===========================================================================\n",
    "noiseFactor = 1\n",
    "\n",
    "#===========================================================================\n",
    "# Decide wether gestures shall be shuffled before training. If true, nFolds many \n",
    "# pieces will be generated. Not every piece is garanteed to contain every gesture, so do not use too many.\n",
    "#===========================================================================\n",
    "shuffle = True\n",
    "nFolds = 4\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Function used to evaluate during cross validation. Possible functions are:\n",
    "# Evaluation.calc1MinusF1FromMaxApp (best working, used in thesis)\n",
    "# Oger.utils.nmse (normalised mean square error, tells nothing about classifier perfomance but works okay)\n",
    "# Evaluation.calcLevenshteinError (use the Levenshtein error, disadvantages are highlighted in thesis) \n",
    "# Evaluation.calc1MinusF1FromInputSegment (use segmentation by supervised signal)\n",
    "#===========================================================================\n",
    "evaluationFunction = Evaluation.calc1MinusF1FromMaxApp\n",
    "\n",
    "#===========================================================================\n",
    "# Set this to true if another output neuron shall be added to represent \"no gesture\"\n",
    "#===========================================================================\n",
    "learnTreshold = True\n",
    "\n",
    "#===========================================================================\n",
    "# Use on of the optimisation dictionaries from the optDicts file\n",
    "#===========================================================================\n",
    "optDict = 'bestParas'\n",
    "\n",
    "#===========================================================================\n",
    "# Use normalizer\n",
    "#===========================================================================\n",
    "useNormalized = 2\n",
    "\n",
    "#===========================================================================\n",
    "# Pick datasets to train on, and datasets to test on\n",
    "#===========================================================================\n",
    "inputFiles = ['nike','julian','nadja','line']\n",
    "testFiles = ['stephan']\n",
    "\n",
    "# If desired add a specific file to test on, e.g. randTestFiles = ['lana_0_0.npz']\n",
    "randTestFiles = []\n",
    "\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Setup project directory\n",
    "#===========================================================================\n",
    "now = datetime.datetime.now()\n",
    "resultsPath = getProjectPath()+'results/'\n",
    "pdfFileName = now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.pdf'\n",
    "pdfFilePath = resultsPath+'pdf/'+pdfFileName\n",
    "npzFileName = now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.npz'\n",
    "npzFilePath = resultsPath+'npz/'+npzFileName\n",
    "bestFlowPath = resultsPath+'nodes/'+now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.p'\n",
    "pp = PdfPages(pdfFilePath)\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Add labels for gestures\n",
    "#===========================================================================\n",
    "totalGestureNames = ['left','right','forward','backward','bounce up','bounce down','turn left','turn right','shake lr','shake ud', \\\n",
    "                     'tap 1','tap 2','tap 3','tap 4','tap 5','tap 6','no gesture']\n",
    "gestureNames = []\n",
    "for i in usedGestures:\n",
    "    gestureNames.append(totalGestureNames[i])\n",
    "gestureNames.append('no gesture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = UniHHIMUGestures(dataDir='dataSets/', train=True, useNormalized=useNormalized)\n",
    "testset = UniHHIMUGestures(dataDir='dataSets/', train=False, useNormalized=useNormalized)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=1,\n",
    "                        shuffle=True, num_workers=1)\n",
    "testloader = DataLoader(testset, batch_size=1,\n",
    "                        shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the scaled input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(20,9))\n",
    "ax[0].plot(trainset[0][0][:800,0:3])\n",
    "ax[1].plot(trainset[0][0][:800,3:6])\n",
    "ax[2].plot(trainset[0][0][:800,6:9])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks all good, we can clearly see the gesture sequences intercepted by non gesture seqeuences in between.\n",
    "Now let's create a Leaky Integrator ESN with parameters as defined in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from echotorch.nn.ESN import ESN\n",
    "from echotorch.nn.LiESN import LiESN\n",
    "\n",
    "\n",
    "\n",
    "esn = LiESN(\n",
    "    input_dim=9,\n",
    "    hidden_dim=400,\n",
    "    output_dim=10,\n",
    "    input_scaling=13.,\n",
    "    sparsity=0.1, # input matrix sparsity\n",
    "    w_distrib='gaussian',\n",
    "    spectral_radius=1.,\n",
    "    bias_scaling=0., # no input bias\n",
    "    feedbacks=False, # No feedback connections\n",
    "    learning_algo='inv',\n",
    "    leaky_rate=.3\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Training is done automatically when presenting the values and targets to the network. After calling finalize training is completed and network switches to prediction mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for inputs, targets in trainloader:\n",
    "    inputs, targets = Variable(inputs.float()), Variable(targets.float())\n",
    "    esn(inputs, targets)\n",
    "    \n",
    "esn.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Plot activations of network on testset and corresponding target signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_inputs, test_targets in testloader:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    outputs = esn(test_inputs.float())\n",
    "    plt.plot(outputs[0,:800,:])\n",
    "    plt.plot(test_targets[0,:800,:])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "trainCms = []\n",
    "trainF1MaxApps = []\n",
    "trainPredicitions = []\n",
    "trainTargets = []\n",
    "trainF1s = []\n",
    "\n",
    "prediction = outputs[0].numpy()\n",
    "t_target =  test_targets[0].numpy()\n",
    "\n",
    "pred, targ = Evaluation.calcInputSegmentSeries(prediction, t_target, 0.4, False)\n",
    "trainF1s.append(np.mean(sklearn.metrics.f1_score(targ,pred,average=None)))\n",
    "\n",
    "\n",
    "t_maxApp_prediction = Evaluation.calcMaxActivityPrediction(prediction,t_target,0.5,10)\n",
    "pred_MaxApp, targ_MaxApp = Evaluation.calcInputSegmentSeries(t_maxApp_prediction, t_target, 0.5)\n",
    "trainF1MaxApps.append(np.mean(sklearn.metrics.f1_score(targ_MaxApp,pred_MaxApp,average=None)))\n",
    "\n",
    "conf = sklearn.metrics.confusion_matrix(targ_MaxApp, pred_MaxApp)\n",
    "trainCms.append(conf)\n",
    "trainPredicitions.append(prediction)\n",
    "trainTargets.append(t_target)\n",
    "\n",
    "Evaluation.plot_confusion_matrix(trainCms[0], gestureNames, 'test set')\n",
    "plt.tight_layout()\n",
    "plt.ylim(10.5,-0.5)\n",
    "\n",
    "print(\"Test f1 score for maxactivity: {:.2f}\".format(trainF1MaxApps[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: why is the testscore here lower than in OGER? supposed to be 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "Create and train LSTM on the give data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=25):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_size=9, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim,10, bias=False),\n",
    "            #torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        \n",
    "        lstm_outputs, (hidden_acts, cell_states) = self.lstm(inputs)\n",
    "        predictions = self.classifier(lstm_outputs)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lstm = LSTMClassifier(25)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = optim.SGD(lstm.parameters(), lr=1e-1)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    for inputs, targets in trainloader:\n",
    "\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        \n",
    "        inputs[0,:,:9] = targets[0,:,:9]\n",
    "\n",
    "        lstm.zero_grad()\n",
    "\n",
    "        outputs =  lstm(inputs)\n",
    "\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        lstm.lstm\n",
    "        \n",
    "        optimizer.step()\n",
    "    if epoch % 2 == 0:\n",
    "        print(loss.item())\n",
    "        lstm.eval()\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.title('Epoch: {:}, loss: {:.4f}'.format(epoch, loss))\n",
    "        test_preds = lstm(test_inputs.float()).detach().numpy()[0]\n",
    "        plt.plot(test_preds[:800,:])\n",
    "        plt.plot(test_targets[0,:800,:])\n",
    "        plt.ylim(-0.1,1.1)\n",
    "        plt.pause(1)\n",
    "        lstm.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.eval()\n",
    "plt.figure(figsize=(20,5))\n",
    "test_preds = lstm(test_inputs.float()).detach().numpy()[0]\n",
    "plt.plot(test_preds[:800,:])\n",
    "plt.pause(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
