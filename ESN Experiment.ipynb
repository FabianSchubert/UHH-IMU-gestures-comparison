{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESN Experiment\n",
    "\n",
    "This notebook reproduces the results in the paper ...\n",
    "\n",
    "It consits of three parts:\n",
    "\n",
    "1. An example for how to set up and experiment and use the code to train an ESN on the data.\n",
    "2. A section to reproduce the scores mentioned in the paper for each testset.\n",
    "3. A section to measure training time of an echo state network on our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataSet\n",
    "import Evaluation\n",
    "import datetime\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from Utils import *\n",
    "\n",
    "from DataSet import UniHHIMUGestures\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualSeed = 1\n",
    "\n",
    "np.random.seed(manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "# if you are suing GPU\n",
    "torch.cuda.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "\n",
    "#torch.backends.cudnn.enabled = False \n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a bunch of parameters the expriment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================================================\n",
    "# Give this run a name. \n",
    "# If name equals 'test', no log will be generated\n",
    "#===========================================================================\n",
    "name = 'test'\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Decide which gesture data shall be used for training\n",
    "#===========================================================================\n",
    "inputGestures = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "#===========================================================================\n",
    "# Decide which target signals shall be used for training\n",
    "#===========================================================================\n",
    "usedGestures = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "#===========================================================================\n",
    "# Concatenate data to create \"more\" training samples, 1 corresponds to no concatenations\n",
    "#===========================================================================\n",
    "concFactor = 1\n",
    "\n",
    "#===========================================================================\n",
    "# Add noise to the data, 0 corresponds to no noise. Noise above 2 has shown to weaken recognition\n",
    "#===========================================================================\n",
    "noiseFactor = 1\n",
    "\n",
    "#===========================================================================\n",
    "# Decide wether gestures shall be shuffled before training. If true, nFolds many \n",
    "# pieces will be generated. Not every piece is garanteed to contain every gesture, so do not use too many.\n",
    "#===========================================================================\n",
    "shuffle = True\n",
    "nFolds = 4\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Function used to evaluate during cross validation. Possible functions are:\n",
    "# Evaluation.calc1MinusF1FromMaxApp (best working, used in thesis)\n",
    "# Oger.utils.nmse (normalised mean square error, tells nothing about classifier perfomance but works okay)\n",
    "# Evaluation.calcLevenshteinError (use the Levenshtein error, disadvantages are highlighted in thesis) \n",
    "# Evaluation.calc1MinusF1FromInputSegment (use segmentation by supervised signal)\n",
    "#===========================================================================\n",
    "evaluationFunction = Evaluation.calc1MinusF1FromMaxApp\n",
    "\n",
    "#===========================================================================\n",
    "# Set this to true if another output neuron shall be added to represent \"no gesture\"\n",
    "#===========================================================================\n",
    "learnTreshold = False\n",
    "\n",
    "#===========================================================================\n",
    "# Use on of the optimisation dictionaries from the optDicts file\n",
    "#===========================================================================\n",
    "optDict = 'bestParas'\n",
    "\n",
    "#===========================================================================\n",
    "# Use normalizer\n",
    "#===========================================================================\n",
    "useNormalized = 2\n",
    "\n",
    "#===========================================================================\n",
    "# Pick datasets to train on, and datasets to test on\n",
    "#===========================================================================\n",
    "inputFiles = ['stephan','julian','nadja','line']\n",
    "testFiles = ['nike']\n",
    "\n",
    "# If desired add a specific file to test on, e.g. randTestFiles = ['lana_0_0.npz']\n",
    "randTestFiles = []\n",
    "\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Setup project directory\n",
    "#===========================================================================\n",
    "now = datetime.datetime.now()\n",
    "resultsPath = getProjectPath()+'results/'\n",
    "pdfFileName = now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.pdf'\n",
    "pdfFilePath = resultsPath+'pdf/'+pdfFileName\n",
    "npzFileName = now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.npz'\n",
    "npzFilePath = resultsPath+'npz/'+npzFileName\n",
    "bestFlowPath = resultsPath+'nodes/'+now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.p'\n",
    "pp = PdfPages(pdfFilePath)\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Add labels for gestures\n",
    "#===========================================================================\n",
    "totalGestureNames = ['left','right','forward','backward','bounce up','bounce down','turn left','turn right','shake lr','shake ud', \\\n",
    "                     'tap 1','tap 2','tap 3','tap 4','tap 5','tap 6','no gesture']\n",
    "gestureNames = []\n",
    "for i in usedGestures:\n",
    "    gestureNames.append(totalGestureNames[i])\n",
    "gestureNames.append('no gesture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createData(inputFiles, testFiles):\n",
    "    trainset = UniHHIMUGestures(dataDir='dataSets/', \n",
    "                                train=True, \n",
    "                                inputFiles=inputFiles,\n",
    "                                testFiles=testFiles,\n",
    "                                useNormalized=useNormalized, \n",
    "                                learnTreshold=learnTreshold,\n",
    "                                shuffle=True,\n",
    "                               )\n",
    "\n",
    "    testset = UniHHIMUGestures(dataDir='dataSets/', \n",
    "                               train=False, \n",
    "                               inputFiles=inputFiles,\n",
    "                               testFiles=testFiles,\n",
    "                               useNormalized=useNormalized, \n",
    "                               learnTreshold=learnTreshold,\n",
    "                               shuffle=True\n",
    "                              \n",
    "                              )\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=1,\n",
    "                            shuffle=True, num_workers=1)\n",
    "    testloader = DataLoader(testset, batch_size=1,\n",
    "                            shuffle=True, num_workers=1)\n",
    "    return trainset, testset, trainloader, testloader\n",
    "    \n",
    "trainset, testset, trainloader, testloader = createData(inputFiles, testFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the scaled input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(20,9))\n",
    "ax[0].plot(trainset[0][0][:800,0:3])\n",
    "ax[1].plot(trainset[0][0][:800,3:6])\n",
    "ax[2].plot(trainset[0][0][:800,6:9])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks all good, we can clearly see the gesture sequences intercepted by non gesture seqeuences in between.\n",
    "Now let's create a Leaky Integrator ESN with parameters as defined in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from echotorch.nn.ESN import ESN\n",
    "from echotorch.nn.LiESN import LiESN\n",
    "\n",
    "\n",
    "def createESN():\n",
    "    esn = LiESN(\n",
    "        input_dim=9,\n",
    "        hidden_dim=400,\n",
    "        output_dim=10 if not learnTreshold else 11,\n",
    "        input_scaling=13.,\n",
    "        sparsity=0.1, # input matrix sparsity\n",
    "        w_distrib='gaussian',\n",
    "        spectral_radius=1.,\n",
    "        bias_scaling=0., # no input bias\n",
    "        feedbacks=False, # No feedback connections\n",
    "        learning_algo='inv',\n",
    "        leaky_rate=.3\n",
    "    )\n",
    "    return esn\n",
    "\n",
    "esn = createESN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Training is done automatically when presenting the values and targets to the network. After calling finalize training is completed and network switches to prediction mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def trainESN(trainloader, esn):\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs, targets = Variable(inputs.float()), Variable(targets.float())\n",
    "        esn(inputs, targets)\n",
    "\n",
    "    esn.finalize()\n",
    "\n",
    "\n",
    "trainESN(trainloader, esn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Plot activations of network on testset and corresponding target signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_inputs, test_targets in testloader:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    outputs = esn(test_inputs.float())\n",
    "    if learnTreshold:\n",
    "        plt.plot(outputs[0,:800,10], c='black')\n",
    "    plt.plot(outputs[0,:800,:10])\n",
    "    plt.plot(test_targets[0,:800,:])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "def testESN(testloader, learnTreshold, fixed_threshold=0.4, plot=False):\n",
    "    \n",
    "    for test_inputs, test_targets in testloader:\n",
    "        outputs = esn(test_inputs.float())\n",
    "    \n",
    "        testCms = []\n",
    "        testF1MaxApps = []\n",
    "\n",
    "        t_target = test_targets[0].numpy()\n",
    "        prediction = outputs[0].numpy()[:,:10]\n",
    "        if learnTreshold: # if threshold is learned, then it's the last collumn of the prediction\n",
    "            threshold = outputs[0].numpy()[:,10]\n",
    "        else: #else add a constant threshold\n",
    "            threshold = np.ones((prediction.shape[0],1))*fixed_threshold\n",
    "\n",
    "        t_maxApp_prediction = Evaluation.calcMaxActivityPrediction(prediction,t_target,threshold, 10)\n",
    "\n",
    "\n",
    "        pred_MaxApp, targ_MaxApp = Evaluation.calcInputSegmentSeries(t_maxApp_prediction, t_target, 0.5)\n",
    "        testF1MaxApps.append(np.mean(sklearn.metrics.f1_score(targ_MaxApp,pred_MaxApp,average=None)))\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(20,3))\n",
    "            plt.plot(t_maxApp_prediction[:800])\n",
    "            plt.plot(t_target[:800])\n",
    "\n",
    "\n",
    "        conf = sklearn.metrics.confusion_matrix(targ_MaxApp, pred_MaxApp)\n",
    "        testCms.append(conf)\n",
    "\n",
    "        if plot:\n",
    "            Evaluation.plot_confusion_matrix(testCms[0], gestureNames, 'test set')\n",
    "            plt.tight_layout()\n",
    "            plt.ylim(10.5,-0.5)\n",
    "\n",
    "        print(\"Test f1 score for maxactivity algorithm on testsets {} is {:.2f} \".format(\n",
    "            testFiles, np.mean(testF1MaxApps)))\n",
    "    return testF1MaxApps\n",
    "\n",
    "f1scores = testESN(testloader, learnTreshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Evaluate on different Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = ['stephan','julian','nadja','line','nike']\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for idx in range(5):\n",
    "    scores = []\n",
    "    \n",
    "    # Shuffle testsets\n",
    "    inputFiles = files[:idx] + files[idx+1:]\n",
    "    testFiles = files[idx:idx+1]\n",
    "\n",
    "\n",
    "    for _ in range(10):\n",
    "        trainset, testset, trainloader, testloader = createData(inputFiles=inputFiles, testFiles=testFiles)\n",
    "        esn = createESN()\n",
    "        trainESN(trainloader, esn)\n",
    "        \n",
    "        if False:\n",
    "            totalTrainInputData = []\n",
    "            totalTrainTargetData = []\n",
    "            for inputs, targets in trainloader:\n",
    "                totalTrainInputData.append(inputs)\n",
    "                totalTrainTargetData.append(targets)\n",
    "            totalTrainInputData = torch.cat(totalTrainInputData,1)\n",
    "            totalTrainTargetData = torch.cat(totalTrainTargetData,1)\n",
    "            totalTrainInputData = torch.tensor(totalTrainInputData)\n",
    "            totalTrainPrediction = esn(totalTrainInputData.float())\n",
    "\n",
    "            totalTrainPrediction = totalTrainPrediction[0,:,:].numpy()\n",
    "            totalTrainTargetData = totalTrainTargetData[0,:,:].numpy()\n",
    "        \n",
    "            tresholds, _, bestF1ScoreTreshold = Evaluation.calcTPFPForThresholds(totalTrainPrediction, totalTrainTargetData, 'Train Data Confusion - Target Treshold', False, plot=False)\n",
    "        bestF1ScoreTreshold = 0.4\n",
    "        # very good results when bestF1score is set to 0.4\n",
    "        \n",
    "        score = testESN(testloader, learnTreshold, fixed_threshold=bestF1ScoreTreshold)\n",
    "        scores.extend(score)\n",
    "        \n",
    "    print('{}: avg f1 score: {:.2f}, ({:.2f}) '.format(testFiles[0], np.array(scores).mean(),np.array(scores).std()))\n",
    "    all_scores.extend(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean([0.624 - 0.62, 0.791 - 0.79, 0.809 - 0.78, 0.831 - 0.76, 0.926 - 0.88]),\n",
    "np.mean([0.624 - 0.60, 0.791 - 0.79, 0.809 - 0.80, 0.831 - 0.76, 0.926 - 0.86]),)\n",
    "\n",
    "\n",
    "print(\"paper mean: {:.3f}\".format(np.mean([0.624,0.791,0.809,0.831,0.926])))\n",
    "\n",
    "\n",
    "print(\"opti. threshold mean: {:.3f}\".format(np.mean([0.60,0.79,0.80,0.76,0.86])))\n",
    "print(\"fixed threshold mean: {:.3f}\".format(np.mean([0.62,0.79,0.78,0.76,0.88])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Results in comparison:\n",
    "\n",
    "| Test Person   | Paper   | Paper Repro   | Opt. Treshold | Fixed Treshold |\n",
    "| ------------- |:-------:| :-----------: | :-----------: | :------------: |\n",
    "| Julian        | 0.624   | 0.59 (0.04)   | 0.60 (0.04)   | 0.62 (0.04)    |\n",
    "| Nike          | 0.791   | 0.74 (0.05)   | 0.79 (0.03)   | 0.79 (0.04)    |\n",
    "| Stephan       | 0.809   | 0.77 (0.03)   | 0.80 (0.03)   | 0.78 (0.04)    |\n",
    "| Nadja         | 0.831   | 0.79 (0.04)   | 0.76 (0.06)   | 0.76 (0.04)    |\n",
    "| Line          | 0.926   | 0.86 (0.03)   | 0.86 (0.03)   | 0.88 (0.04)    |\n",
    "| ------------- |---------| ------------- | ------------- | ---------------|\n",
    "| Diff paper    |         |               | 0.034         | 0.030          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: why is the testscore here lower than in OGER? supposed to be 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Meassure training time\n",
    "\n",
    "We are using timeit to meassure training time, two repetitions of 10 loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training on: {}\".format(inputFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r2 -n10 \n",
    "esn = createESN()\n",
    "trainESN(trainloader, esn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental code\n",
    "\n",
    "Code below here is experimental and not used in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out softmax\n",
    "\n",
    "Learn threshold must be true for softmax to make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert learnTreshold==True, 'Model must be created with learnThreshold=true to use softmax'\n",
    "\n",
    "for test_inputs, test_targets in testloader:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    outputs = esn(test_inputs.float())\n",
    "    outputs = nn.Softmax(2)(outputs)\n",
    "    if learnTreshold:\n",
    "        plt.plot(outputs[0,:800,10], c='black')\n",
    "    plt.plot(outputs[0,:800,:10])\n",
    "    plt.plot(test_targets[0,:800,:])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcBasicMaxActivation(prediction, t_target, threshold, gestureMinLength=1 ):\n",
    "    inactive_timesteps = prediction.max(1) < threshold\n",
    "    active_timesteps = prediction.max(1) >= threshold\n",
    "\n",
    "    gesture_end = inactive_timesteps[1:] * active_timesteps[:-1]\n",
    "    gesture_start = inactive_timesteps[:-1] * active_timesteps[1:]\n",
    "\n",
    "    predicted_labels = np.zeros(prediction.shape)\n",
    "    for start, end in list(zip(np.where(gesture_start)[0], np.where(gesture_end)[0])):\n",
    "\n",
    "        if end-start > gestureMinLength:\n",
    "            gestureclass = prediction[start:end].sum(0).argmax()\n",
    "            predicted_labels[start:end,gestureclass] = 1\n",
    "    return predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "testCms = []\n",
    "testF1MaxApps = []\n",
    "\n",
    "t_target =  test_targets[0].numpy()\n",
    "prediction = outputs[0].numpy()[:,:10]\n",
    "if learnTreshold: # if threshold is learned, then it's the las collumn of the prediction\n",
    "    threshold = outputs[0].numpy()[:,10]\n",
    "else: #else add a constant threshold\n",
    "    threshold = np.ones((prediction.shape[0],1))*0.4\n",
    "\n",
    "# use different method for maxappactivation\n",
    "t_maxApp_prediction = calcBasicMaxActivation(prediction,t_target,threshold, 10)\n",
    "\n",
    "\n",
    "pred_MaxApp, targ_MaxApp = Evaluation.calcInputSegmentSeries(t_maxApp_prediction, t_target, 0.5)\n",
    "testF1MaxApps.append(np.mean(sklearn.metrics.f1_score(targ_MaxApp,pred_MaxApp,average=None)))\n",
    "\n",
    "\n",
    "#print(t_maxApp_prediction.shape, prediction.shape, pred_MaxApp, targ_MaxApp)\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.plot(t_maxApp_prediction[:800])\n",
    "plt.plot(t_target[:800])\n",
    "\n",
    "\n",
    "conf = sklearn.metrics.confusion_matrix(targ_MaxApp, pred_MaxApp)\n",
    "testCms.append(conf)\n",
    "\n",
    "Evaluation.plot_confusion_matrix(testCms[0], gestureNames, 'test set')\n",
    "plt.tight_layout()\n",
    "plt.ylim(10.5,-0.5)\n",
    "\n",
    "print(\"Test f1 score for maxactivity: {:.2f}, reg: {:.2f}\".format(testF1MaxApps[0], trainF1s[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
