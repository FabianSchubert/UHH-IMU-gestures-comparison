{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gyv1r3eB1qAo"
   },
   "source": [
    "# LSTM Experiment\n",
    "\n",
    "Requieres CUDA to run right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1u7mm60Xjw5"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ak1rmTI8YIey",
    "outputId": "91a6da8f-3299-4915-b5c6-a0d818cf773d"
   },
   "outputs": [],
   "source": [
    "# For use in google colab\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "oLsuMMvvXjxQ",
    "outputId": "70897689-5396-4e6d-d1c2-0d0dac2e618f"
   },
   "outputs": [],
   "source": [
    "import DataSet\n",
    "import Evaluation\n",
    "import datetime\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from Utils import *\n",
    "\n",
    "from DataSet import UniHHIMUGestures\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SnSwJOLXjxi"
   },
   "source": [
    "We need to specify a bunch of parameters the expriment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14Ptf_AhXjxo"
   },
   "outputs": [],
   "source": [
    "#===========================================================================\n",
    "# Give this run a name. \n",
    "# If name equals 'test', no log will be generated\n",
    "#===========================================================================\n",
    "name = 'test'\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Decide which gesture data shall be used for training\n",
    "#===========================================================================\n",
    "inputGestures = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "#===========================================================================\n",
    "# Decide which target signals shall be used for training\n",
    "#===========================================================================\n",
    "usedGestures = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "#===========================================================================\n",
    "# Concatenate data to create \"more\" training samples, 1 corresponds to no concatenations\n",
    "#===========================================================================\n",
    "concFactor = 1\n",
    "\n",
    "#===========================================================================\n",
    "# Add noise to the data, 0 corresponds to no noise. Noise above 2 has shown to weaken recognition\n",
    "#===========================================================================\n",
    "noiseFactor = 1\n",
    "\n",
    "#===========================================================================\n",
    "# Decide wether gestures shall be shuffled before training. If true, nFolds many \n",
    "# pieces will be generated. Not every piece is garanteed to contain every gesture, so do not use too many.\n",
    "#===========================================================================\n",
    "shuffle = True\n",
    "nFolds = 4\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Function used to evaluate during cross validation. Possible functions are:\n",
    "# Evaluation.calc1MinusF1FromMaxApp (best working, used in thesis)\n",
    "# Oger.utils.nmse (normalised mean square error, tells nothing about classifier perfomance but works okay)\n",
    "# Evaluation.calcLevenshteinError (use the Levenshtein error, disadvantages are highlighted in thesis) \n",
    "# Evaluation.calc1MinusF1FromInputSegment (use segmentation by supervised signal)\n",
    "#===========================================================================\n",
    "evaluationFunction = Evaluation.calc1MinusF1FromMaxApp\n",
    "\n",
    "#===========================================================================\n",
    "# Set this to true if another output neuron shall be added to represent \"no gesture\"\n",
    "#===========================================================================\n",
    "learnTreshold = False\n",
    "\n",
    "#===========================================================================\n",
    "# Use on of the optimisation dictionaries from the optDicts file\n",
    "#===========================================================================\n",
    "optDict = 'bestParas'\n",
    "\n",
    "#===========================================================================\n",
    "# Use normalizer\n",
    "#===========================================================================\n",
    "useNormalized = 2\n",
    "\n",
    "#===========================================================================\n",
    "# Pick datasets to train on, and datasets to test on\n",
    "#===========================================================================\n",
    "inputFiles = ['nike','julian','nadja','line']\n",
    "testFiles = ['stephan']\n",
    "\n",
    "# If desired add a specific file to test on, e.g. randTestFiles = ['lana_0_0.npz']\n",
    "randTestFiles = []\n",
    "\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Setup project directory\n",
    "#===========================================================================\n",
    "now = datetime.datetime.now()\n",
    "resultsPath = getProjectPath()+'results/'\n",
    "pdfFileName = now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.pdf'\n",
    "pdfFilePath = resultsPath+'pdf/'+pdfFileName\n",
    "npzFileName = now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.npz'\n",
    "npzFilePath = resultsPath+'npz/'+npzFileName\n",
    "bestFlowPath = resultsPath+'nodes/'+now.strftime(\"%Y-%m-%d-%H-%M\")+'_'+name+'.p'\n",
    "pp = PdfPages(pdfFilePath)\n",
    "\n",
    "\n",
    "#===========================================================================\n",
    "# Add labels for gestures\n",
    "#===========================================================================\n",
    "totalGestureNames = ['left','right','forward','backward','bounce up','bounce down','turn left','turn right','shake lr','shake ud', \\\n",
    "                     'tap 1','tap 2','tap 3','tap 4','tap 5','tap 6','no gesture']\n",
    "gestureNames = []\n",
    "for i in usedGestures:\n",
    "    gestureNames.append(totalGestureNames[i])\n",
    "gestureNames.append('no gesture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-r4Ua_FmXjx1"
   },
   "source": [
    "Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1CKFlNaXjx5"
   },
   "outputs": [],
   "source": [
    "def createData(inputFiles, testFiles):\n",
    "    trainset = UniHHIMUGestures(dataDir='dataSets/', \n",
    "                                train=True, \n",
    "                                inputFiles=inputFiles,\n",
    "                                testFiles=testFiles,\n",
    "                                useNormalized=useNormalized, \n",
    "                                learnTreshold=learnTreshold,\n",
    "                                shuffle=True,\n",
    "                               )\n",
    "\n",
    "    testset = UniHHIMUGestures(dataDir='dataSets/', \n",
    "                               train=False, \n",
    "                               inputFiles=inputFiles,\n",
    "                               testFiles=testFiles,\n",
    "                               useNormalized=useNormalized, \n",
    "                               learnTreshold=learnTreshold,\n",
    "                               shuffle=True\n",
    "                              \n",
    "                              )\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=1,\n",
    "                            shuffle=True, num_workers=1)\n",
    "    testloader = DataLoader(testset, batch_size=1,\n",
    "                            shuffle=True, num_workers=1)\n",
    "    return trainset, testset, trainloader, testloader\n",
    "    \n",
    "trainset, testset, trainloader, testloader = createData(inputFiles, testFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GCQCtfOXjyH"
   },
   "source": [
    "Let's take a look at the scaled input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "id": "wOes7SOnXjyK",
    "outputId": "28dfd889-5ae5-445f-d64c-6f67278d90bc"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(20,9))\n",
    "ax[0].plot(trainset[0][0][:800,0:3])\n",
    "ax[1].plot(trainset[0][0][:800,3:6])\n",
    "ax[2].plot(trainset[0][0][:800,6:9])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f272FhRMXjyj"
   },
   "source": [
    "Looks all good, we can clearly see the gesture sequences intercepted by non gesture seqeuences in between.\n",
    "Now let's create a Leaky Integrator ESN with parameters as defined in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPi2g5rsXj20"
   },
   "source": [
    "# LSTM\n",
    "\n",
    "Create and train LSTM on the give data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHEvdCxdXj3c"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=25):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_size=9, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim,10, bias=False),\n",
    "            #torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        \n",
    "        lstm_outputs, (hidden_acts, cell_states) = self.lstm(inputs)\n",
    "        predictions = self.classifier(lstm_outputs)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "LXVYixr7Xj3p",
    "outputId": "34c3d338-93ad-4ac3-83f4-ab324350e1cb"
   },
   "outputs": [],
   "source": [
    "lstm = LSTMClassifier(20)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=1e-3)\n",
    "\n",
    "lstm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "q5n8a9bqXj4P",
    "outputId": "2e1cb147-9f31-4778-8b51-563ce9ab212c"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "def testLSTM(testloader, lstm, plot=True, plotConf=False):\n",
    "    testF1MaxApps = []\n",
    "    testCms = []\n",
    "    losses = []\n",
    "    for inputs, targets in testloader:\n",
    "        test_inputs, test_targets = inputs.float(), targets.float()\n",
    "        \n",
    "        #inputs[0,:,:9] = targets[0,:,:9]\n",
    "        test_inputs = (test_inputs/test_inputs.std(1))\n",
    "        \n",
    "        test_inputs = test_inputs.cuda()\n",
    "        test_targets = test_targets.cuda()\n",
    "\n",
    "        lstm.eval()\n",
    "\n",
    "\n",
    "        outputs = lstm(test_inputs)\n",
    "        loss = loss_function(outputs, test_targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        test_preds = outputs.cpu().detach().numpy()[0]\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(20,5))\n",
    "            plt.plot(test_preds[:1600,:])\n",
    "            plt.plot(test_targets[0,:1600,:].cpu())\n",
    "            plt.pause(1)\n",
    "        \n",
    "        fixed_threshold = 0.4\n",
    "\n",
    "        t_target = test_targets[0].cpu().numpy()\n",
    "        prediction = test_preds[:,:10]\n",
    "        if learnTreshold: # if threshold is learned, then it's the las collumn of the prediction\n",
    "            threshold = outputs[0].numpy()[:,10]\n",
    "        else: #else add a constant threshold\n",
    "            threshold = np.ones((prediction.shape[0],1))*fixed_threshold\n",
    "\n",
    "        t_maxApp_prediction = Evaluation.calcMaxActivityPrediction(prediction,t_target,threshold, 10)\n",
    "\n",
    "\n",
    "        pred_MaxApp, targ_MaxApp = Evaluation.calcInputSegmentSeries(t_maxApp_prediction, t_target, 0.5)\n",
    "        testF1MaxApps.append(np.mean(sklearn.metrics.f1_score(targ_MaxApp,pred_MaxApp,average=None)))\n",
    "\n",
    "        if False:\n",
    "        #print(t_maxApp_prediction.shape, prediction.shape, pred_MaxApp, targ_MaxApp)\n",
    "            plt.figure(figsize=(20,3))\n",
    "            plt.plot(t_maxApp_prediction[:800])\n",
    "            plt.plot(t_target[:800])\n",
    "\n",
    "\n",
    "        conf = sklearn.metrics.confusion_matrix(targ_MaxApp, pred_MaxApp)\n",
    "        testCms.append(conf)\n",
    "\n",
    "        if plotConf:\n",
    "            Evaluation.plot_confusion_matrix(testCms[0], gestureNames, 'test set')\n",
    "            plt.tight_layout()\n",
    "            plt.ylim(10.5,-0.5)\n",
    "\n",
    "    #print(\"Test f1 score for maxactivity: {:.4f}, MSE: {:.4f}\".format(np.mean(testF1MaxApps),loss.item()))\n",
    "\n",
    "    return np.mean(testF1MaxApps), np.mean(losses)\n",
    "\n",
    "testLSTM(testloader, lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GhmcQw_IXj31",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def trainLSTM(inputFiles, testFiles):\n",
    "    trainset, testset, trainloader, testloader = createData(inputFiles, testFiles)\n",
    "\n",
    "    lstm = LSTMClassifier(20)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    optimizer = optim.Adam(lstm.parameters(), lr=1e-3)\n",
    "\n",
    "    lstm.cuda()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_model = lstm.state_dict()\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_scores = []\n",
    "\n",
    "    for epoch in range(126):\n",
    "        epoch_losses = []\n",
    "        for inputs, targets in trainloader:\n",
    "            lstm.train()\n",
    "            inputs, targets = inputs.float(), targets.float()\n",
    "            \n",
    "            #inputs[0,:,:9] = targets[0,:,:9]\n",
    "            inputs = (inputs/inputs.std(1))\n",
    "            \n",
    "            inputs = inputs[:,:,:].cuda()\n",
    "            targets = targets[:,:,:].cuda()\n",
    "\n",
    "            lstm.zero_grad()\n",
    "\n",
    "            outputs =  lstm(inputs)\n",
    "\n",
    "\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        train_losses.append(epoch_losses)\n",
    "\n",
    "        score, mse = testLSTM(testloader, lstm, plot=False)\n",
    "        test_losses.append(mse.item())\n",
    "        test_scores.append(score.item())\n",
    "\n",
    "        if score > best_score:\n",
    "            torch.save(lstm.state_dict(), 'weights_only.pth')\n",
    "            best_score = score\n",
    "\n",
    "        if epoch % 25 == 0:\n",
    "            print(loss.item())\n",
    "            lstm.eval()\n",
    "            plt.figure(figsize=(20,5))\n",
    "            plt.title('Epoch: {:}, loss: {:.4f}'.format(epoch, loss))\n",
    "            #test_preds = lstm(test_inputs.float()).detach().numpy()[0]\n",
    "            #plt.plot(test_preds[:800,:])\n",
    "            #plt.plot(test_targets[0,:800,:])\n",
    "            preds = lstm(inputs)\n",
    "            plt.plot(preds[0,:800].cpu().detach())\n",
    "            plt.plot(targets[0,:800].cpu().detach())\n",
    "            plt.ylim(-0.1,1.1)\n",
    "            plt.pause(1)\n",
    "            score, mse = testLSTM(testloader,lstm,  plot=False)\n",
    "            print(\"Best score: {:.2f}, current score: {:.2f}\".format(best_score, score, mse))\n",
    "\n",
    "    plt.plot([np.mean(epoch_losses) for epoch_losses in train_losses])\n",
    "    plt.plot([x for x in test_losses])\n",
    "    print('###################################################################')\n",
    "\n",
    "    return score, mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "R4-cQ19lJHdL",
    "outputId": "fca68f9e-6e6a-480d-9b73-89b3ea5dcb42"
   },
   "outputs": [],
   "source": [
    "inputFiles = ['stephan','nike','julian','line']\n",
    "testFiles = ['nadja']\n",
    "\n",
    "scores = []\n",
    "for trial in range(10):\n",
    "    print('################# TRIAL: {} #########################'.format(trial))\n",
    "    score, mse = trainLSTM(inputFiles=inputFiles, testFiles=testFiles)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bvBfSWFkXj38",
    "outputId": "ad4eb908-3747-40b0-f753-8f79a696fe71"
   },
   "outputs": [],
   "source": [
    "best_lstm = LSTMClassifier(20)\n",
    "best_lstm.load_state_dict(torch.load('weights_only.pth'))\n",
    "best_lstm.cuda().eval()\n",
    "\n",
    "testLSTM(testloader, best_lstm, plot=True, plotConf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMit19iLXj4D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz_Hm0RcXj4V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVDpQFllWCYW"
   },
   "source": [
    "Scores for 125 epochs of training on nadja, mean: 0.9143460460123742 (0.05), \n",
    "scores:\n",
    "[0.8181441063473731,\n",
    " 0.9231134101237749,\n",
    " 0.9137734105891174,\n",
    " 0.9391169931097335,\n",
    " 0.9671708916560177,\n",
    " 0.9419715272829966,\n",
    " 0.8996514255373884,\n",
    " 0.8261919621187356,\n",
    " 0.9544290335413912,\n",
    " 0.9598976998172137]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "bAW7oqFO5YZ7",
    "outputId": "10b19459-567c-4f48-f690-6ff9a50759ee"
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Q4EGI3yW92Lq",
    "outputId": "6de91c42-2858-4981-8b0b-7eaadf9a3555"
   },
   "outputs": [],
   "source": [
    "np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1W2d0Pj9_AS"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0-ufW_2-Blc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCfmb0Fz-1Fj"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUq0-EUe-5O1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "at8ftn-c-_2P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzuAYiao-IhS"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uF-fHi3o_E3_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzjuJ5YJAcAg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mbf-Ee7yA0Uk",
    "outputId": "b62f07f8-3094-4ec1-9fda-b1378b175e7b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Doreen Paper Main LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
